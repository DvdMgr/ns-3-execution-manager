#+title: Simulation Execution Manager development diary
#+author: Davide Magrin

* Timeline
** Week 1
*** DONE Build a folder structure for the project
**** Project location
     For now, the project will live inside ~ns-3-dev/stats/utils~.
**** Packaging
     I'd like the project to be properly packaged, and available through [[https://pypi.org][pypi]].
     Because of this, I've been following [[https://packaging.python.org/tutorials/distributing-packages/][this guide]] to set the project folder
     structure up.
***** ~twine~ installation
      ~twine~ is required to upload to pypi.
***** setup.py
      The setup.py file was built from [[https://github.com/pypa/sampleproject/blob/master/setup.py][this template]].
****** Look into entry points
       Entry points allow us to specify how the library can be invoked from the
       command line. This could be useful to provide an interactive interface
       to the ns-3 simulation configuration and execution. I'll look into this
       in the future as a possible development to provide a better interface.
***** Building wheels
      Python Wheels can be built using the following command:
      #+BEGIN_SRC shell
      python setup.py bdist_wheel --universal
      #+END_SRC
***** Development workflow example
      The package can be installed as editable with:
      #+BEGIN_SRC shell
      pipenv install --dev -e .
      #+END_SRC

      After installation, use
      #+BEGIN_SRC shell
      pipenv shell
      #+END_SRC
      to start a sub-shell using the appropriate virtual environment.
*** DONE Think about API structure
    Besides from this document, commented drafts of the most relevant functions
    are provided in the =sem= directory.

    This round of API definitions should lay a foundation for the development of
    the library, up to the first milestone. It will define the object structure
    and the interfaces that are required to perform the following functions:
    - Manage a campaign object (both created from scratch and created from an
      existing database)
    - Perform simulations (sequentially)
    - Export results to a =numpy= array

    A =CampaignManager= class will be central to all tasks. This class will
    be the main interface between the user and the Simulation Execution Manager
    (SEM) subsystem, and when necessary it will offload work to two other
    components:
    - A =DatabaseManager=, facilitating access to the campaign database;
    - A =SimulationRunner=, managing the interface with C++ code and running
      simulations.
**** Campaign configuration
     A simulation campaign can be either created from scratch (and immediately
     saved on an associated database file) or loaded from an existing database
     file. In either case, a simulation campaign is completely specified by its
     =campaign.json= file, which contains both the configuration and a
     collection of the currently available results. In order to do this, two
     =@classmethods= are defined, which allow users to specify either a new or
     an existing campaign. Both =@classmethods= then refer to the same
     =__init__= method, which requires a =DatabaseManager= instance as an
     argument.

     The data structure required for the creation of a new campaign will be
     comprised of the following data:
     - Name of associated simulation script (provided by the user);
     - ns-3 installation path (provided by the user);
     - Simulation campaign commit hash (read using the ns-3 installation path);
     - Available script parameters (read from the ns-3 script's help message).

     The above data will be saved to file using the =TinyDB= library, which will
     be exclusively used by the =DatabaseManager= object, acting as an interface
     to provide a simpler way for the =CampaignManager= and =SimulationRunner=
     objects to access the database when necessary.

     Available parameters are extracted at campaign creation time from the
     script's help message, via the =--PrintHelp= option and an appropriate. In
     order to do this, the =CampaignManager= will leverage the utilities
     provided by the =SimulationRunner= object in order to query the script.
     The collected output will then be parsed to extract the list of available
     parameters.

     The current commit of the project is also saved at creation, and compared
     with the current commit before each simulation is run. In case these don't
     match, an error is thrown. =GitPython= is used to interface with the =ns-3=
     repository - support for =Mercurial= repositories is considered a secondary
     feature, seen the migration plans that are being discussed at the moment.

     The Python library =PrettyPrint= will be used to output dictionaries and
     other data structures in a human-readable way.
**** Simulation running
     A =CampaignManager= can be used to run simulations belonging to a parameter
     space. A parameter space is a dictionary containing an entry for each
     parameter made available by the script in the form of command line
     arguments, where the key is the name of the parameter and the value is a
     list of values for that parameter. Additionally, a parameter space also
     needs to contain a =runs= entry, describing the number of runs that are
     desired for each parameter combination.

     What the =CampaignManager= will do is call a =SimulationRunner= function to
     create a list of all possible parameter combinations starting from the
     given parameter space dictionary, and query each one of them against what
     is already available in the campaign database. The =SimulationRunner=
     object, providing functions to perform one-shot executions of the script
     with various parameter combinations, will then gather the remaining
     results.
**** Result management
     Results will be made available from the =CampaignManager= via a
     =get_results_as_numpy_array= function.
**** Database structure
     The database will be divided in two main entries, one containing the
     configuration and one containing the results. The configuration part will
     contain the data that was required for the creation of the database, and
     was described above.

     Thanks to the document-oriented nature of =TinyDB=, results will be saved
     as dictionary entries, describing the parameter combination that was used
     to obtain them. The contents of a typical result will be the following:
     - An entry for each parameter, with the corresponding value;
     - The =GlobalRun= parameter that was used to run the simulation;
     - The =STDOUT= of the script;
     - Any output files generated by the script.
*** Notes
    On my Arch system, compilation is broken because of warnings coming from the
    gtk2 headers: since all warnings are treated as errors by default,
    compilation fails. I've read online that this could be solved by using the
    =-isystem= flag instead of =-I= for system libraries. In the meanwhile, I'm
    configuring with the =--disable-gtk= flag to avoid compilation of the
    relevant =ConfigStore= files.
* Other notes
